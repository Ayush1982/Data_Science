{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact he validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Independence**: Observations within each group must be independent of each other. This means that the value of one observation should not be influenced by the value of another observation.\n",
    "\n",
    "2. **Normality**: The data within each group should follow a normal distribution. This means that when you plot the data for each group on a histogram, it should resemble a bell-shaped curve.\n",
    "\n",
    "3. **Homogeneity of Variance (Homoscedasticity)**: The variance of the data should be consistent across all groups, meaning that the spread of data points around the mean should be approximately equal for all groups.\n",
    "\n",
    " assumptions can impact the validity of ANOVA results:\n",
    "\n",
    "1. **Independence Violation**: Violation of independence can occur when data points within groups are not independent. For example, in a repeated measures design where the same subjects are measured multiple times, the observations may be correlated, violating the independence assumption. This can lead to inflated Type I error rates.\n",
    "\n",
    "2. **Normality Violation**: If the data within groups do not follow a normal distribution, ANOVA results may be unreliable, especially for small sample sizes. For example, if the data are heavily skewed or have outliers, the assumption of normality may be violated. In such cases, using non-parametric alternatives to ANOVA, such as the Kruskal-Wallis test, may be more appropriate.\n",
    "\n",
    "3. **Homogeneity of Variance Violation**: When the assumption of homogeneity of variance is violated, it can lead to incorrect conclusions about group differences. This is particularly problematic if one group has much larger variability compared to others. Common consequences include inflated Type I error rates and reduced power. Techniques such as Welch's ANOVA or robust ANOVA can be used as alternatives in such cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three types of ANOVA are:\n",
    "\n",
    "1. **One-Way ANOVA (One-Factor ANOVA)**:\n",
    "   - Situation: One-Way ANOVA is used when there is one categorical independent variable with three or more levels/groups, and the researcher wants to compare the means of a continuous dependent variable across these groups.\n",
    "   - Example: A psychologist wants to compare the effectiveness of three different therapies (group 1: Cognitive-Behavioral Therapy, group 2: Interpersonal Therapy, group 3: Psychodynamic Therapy) in reducing symptoms of depression among participants.\n",
    "\n",
    "2. **Two-Way ANOVA (Two-Factor ANOVA)**:\n",
    "   - Situation: Two-Way ANOVA is used when there are two categorical independent variables (factors) and one continuous dependent variable. It allows for the examination of the main effects of each independent variable as well as their interaction effect on the dependent variable.\n",
    "   - Example: A biologist wants to investigate the effects of two factors, temperature (high, low) and nutrient availability (low, medium, high), on the growth rate of a particular species of plants.\n",
    "\n",
    "3. **Repeated Measures ANOVA (Within-Subjects ANOVA)**:\n",
    "   - Situation: Repeated Measures ANOVA is used when the same subjects are measured multiple times under different conditions or at different time points. It is suitable for designs where each participant serves as their control, or when measuring changes over time within the same group of participants.\n",
    "   - Example: A researcher wants to assess the effect of three different types of exercise (e.g., running, cycling, swimming) on participants' heart rate, with each participant performing all three types of exercise on separate occasions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Between-Group Variance (SSB)**: This component of variance represents the variability in the dependent variable that is due to differences between the group means. It reflects the extent to which the groups differ from each other on the outcome variable.\n",
    "\n",
    "2. **Within-Group Variance (SSW)**: Also known as the error variance, this component represents the variability in the dependent variable that is not explained by the differences between group means. It reflects the variability within each group, including random variability and measurement error.\n",
    "\n",
    "3. **Total Variance (SST)**: This is the overall variability in the dependent variable across all observations. It is the sum of the between-group variance and the within-group variance.\n",
    "\n",
    "Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "1. **Interpretation of Results**: By understanding how the total variance is partitioned into between-group and within-group components, researchers can interpret the significance of group differences more accurately. For example, a large between-group variance relative to the within-group variance suggests that group differences are meaningful and not simply due to random variability.\n",
    "\n",
    "2. **Effect Size Estimation**: The partitioning of variance allows researchers to calculate effect sizes, such as eta-squared (η²) or partial eta-squared (ηp²), which indicate the proportion of variance in the dependent variable that can be attributed to the independent variable(s). This helps to quantify the practical significance of the observed group differences.\n",
    "\n",
    "3. **Assessment of Model Fit**: Understanding how well the ANOVA model fits the data requires examining the proportion of total variance explained by the model (i.e., the explained variance or R²). This assessment informs researchers about the adequacy of the model in capturing the variability in the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 64.25\n",
      "SSE: 24.83333333333333\n",
      "SSR: 39.41666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "g1 = [10, 12, 14, 15]\n",
    "g2 = [8, 9, 11]\n",
    "g3 = [7, 9, 10, 11, 13]\n",
    "\n",
    "data = np.concatenate([g1, g2, g3])\n",
    "overall_mean = np.mean(data)\n",
    "n = len(data)\n",
    "k = 3\n",
    "SST = np.sum((data - overall_mean) ** 2)\n",
    "\n",
    "\n",
    "SSE = np.sum([len(group) * (np.mean(group) - overall_mean) ** 2 for group in [g1, g2, g3]])\n",
    "SSR = SST - SSE\n",
    "print(\"SST:\", SST)\n",
    "print(\"SSE:\", SSE)\n",
    "print(\"SSR:\", SSR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "data = {'A': [10, 20, 30, np.nan, 50],\n",
    "        'B': [5, 10, 15, 20, 25],\n",
    "        'Y': [15, 25, np.nan, 45, 55]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "if np.any(np.isinf(df)):\n",
    "    raise ValueError(\"DataFrame contains infinite values.\")\n",
    "\n",
    "if df.isnull().values.any():\n",
    "    raise ValueError(\"DataFrame contains NaN values.\")\n",
    "\n",
    "model = ols('Y ~ C(A) + C(B) + C(A):C(B)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "main_effects = anova_table['sum_sq'][:-1] / anova_table['sum_sq'].sum()\n",
    "print(\"\\nMain Effects:\")\n",
    "print(main_effects)\n",
    "interaction_effect = anova_table.loc['C(A):C(B)', 'sum_sq'] / anova_table['sum_sq'].sum()\n",
    "print(\"\\nInteraction Effect:\")\n",
    "print(interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the F-statistic is used to test whether there are significant differences between the means of the groups. The associated p-value tells us the probability of observing such an extreme F-statistic if the null hypothesis (i.e., no difference between group means) were true.\n",
    "\n",
    "In this scenario:\n",
    "\n",
    "- F-statistic: 5.23\n",
    "- p-value: 0.02\n",
    "\n",
    "Since the p-value (0.02) is less than the conventional significance level of 0.05, we reject the null hypothesis. This indicates that there are significant differences between the means of the groups.\n",
    "\n",
    "The results of the one-way ANOVA suggest that there are statistically significant differences between at least two of the groups. However, it does not tell us specifically which groups are different from each other. To determine the specific differences between groups, post-hoc tests (e.g., Tukey's HSD, Bonferroni correction, etc.) can be conducted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA requires careful consideration, as missing data can potentially bias the results and reduce statistical power. There are several methods to handle missing data in repeated measures ANOVA \n",
    "1. **Complete Case Analysis (Listwise Deletion)**:\n",
    "   - This approach involves analyzing only the cases with complete data across all time points or conditions.\n",
    "   - Potential Consequences: This method may lead to biased estimates and reduced statistical power if the missing data are not missing completely at random (MCAR). Additionally, this method discards valuable information from partially complete cases.\n",
    "\n",
    "2. **Mean Imputation**:\n",
    "   - Missing values are replaced with the mean of the observed values for that variable.\n",
    "   - Potential Consequences: Mean imputation can distort the distribution of the data and lead to underestimation of standard errors. It also reduces variability and can inflate statistical significance if the missing data are not MCAR.\n",
    "\n",
    "3. **Last Observation Carried Forward (LOCF)**:\n",
    "   - Missing values are replaced with the value of the last observed measurement.\n",
    "   - Potential Consequences: LOCF may inaccurately reflect changes over time, especially if the missing data are due to dropout or non-random reasons. It can also introduce bias if the last observation is not representative of the true underlying value.\n",
    "\n",
    "4. **Multiple Imputation**:\n",
    "   - This method involves creating multiple imputed datasets, where missing values are replaced with plausible values based on observed data and model assumptions. Analyses are then conducted on each imputed dataset, and results are combined using appropriate rules.\n",
    "   - Potential Consequences: Multiple imputation is generally considered a more robust method compared to single imputation techniques. However, it requires careful consideration of model assumptions and may be computationally intensive.\n",
    "\n",
    "5. **Mixed Effects Models (Including Missing Data Mechanistically)**:\n",
    "   - Mixed effects models (e.g., linear mixed models) can handle missing data by including all available data in the analysis and estimating missing values based on the observed data and the model's fixed and random effects.\n",
    "   - Potential Consequences: Mixed effects models provide valid estimates under the missing at random (MAR) assumption, which assumes that the probability of missingness depends on observed data but not on unobserved data. However, violations of the MAR assumption can bias results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Tukey's Honestly Significant Difference (HSD)**:\n",
    "   - Tukey's HSD test is used when all pairwise comparisons between groups need to be examined.\n",
    "   - Example: After conducting a one-way ANOVA to compare the effectiveness of three different teaching methods on student performance, Tukey's HSD test can be used to determine which pairs of teaching methods lead to significantly different outcomes.\n",
    "\n",
    "2. **Bonferroni Correction**:\n",
    "   - The Bonferroni correction adjusts the significance level (alpha) to control for the increased probability of Type I errors when conducting multiple pairwise comparisons.\n",
    "   - Example: In a study comparing the effectiveness of multiple drug treatments on pain relief, the Bonferroni correction can be applied to assess pairwise differences while controlling the overall familywise error rate.\n",
    "\n",
    "3. **Sidak Correction**:\n",
    "   - Similar to the Bonferroni correction, the Sidak correction adjusts the significance level to maintain the familywise error rate when conducting multiple comparisons.\n",
    "   - Example: In a clinical trial comparing the efficacy of four different treatment regimens for a particular medical condition, the Sidak correction can be used to assess pairwise differences while controlling for the overall probability of making at least one Type I error.\n",
    "\n",
    "4. **Dunnett's Test**:\n",
    "   - Dunnett's test is used when comparing multiple treatment groups to a single control group.\n",
    "   - Example: In a study evaluating the effectiveness of several new drugs compared to a standard treatment (control group) for a specific disease, Dunnett's test can be used to determine which drugs result in significantly different outcomes compared to the control.\n",
    "\n",
    "5. **Holm's Sequential Bonferroni Procedure**:\n",
    "   - Holm's method is a step-down procedure that adjusts the significance level sequentially to maintain the familywise error rate.\n",
    "   - Example: In a study comparing the performance of multiple marketing strategies on sales revenue, Holm's procedure can be used to assess pairwise differences while controlling for the overall probability of Type I error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 6.683404389704723\n",
      "p-value: 0.002175525555059089\n",
      "The p-value is less than 0.05, indicating that there are significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "diet_A = np.array([2.3, 3.5, 1.8, 2.9, 4.2, 3.0, 2.5, 3.1, 2.7, 3.8,\n",
    "                   2.2, 3.6, 1.9, 3.2, 2.4, 3.7, 2.1, 3.3, 2.6, 3.9,\n",
    "                   2.0, 3.4, 2.8, 3.5, 2.3])\n",
    "diet_B = np.array([3.1, 4.2, 2.5, 3.6, 2.8, 4.0, 3.3, 4.1, 3.4, 4.5,\n",
    "                   3.0, 4.3, 2.7, 3.8, 3.2, 4.4, 2.9, 4.1, 3.5, 4.6,\n",
    "                   2.6, 3.9, 3.3, 4.2, 2.8])\n",
    "diet_C = np.array([2.8, 3.9, 2.2, 3.3, 2.5, 3.7, 3.0, 3.8, 2.9, 4.0,\n",
    "                   2.7, 3.6, 2.3, 3.4, 2.6, 3.5, 2.4, 3.2, 2.8, 3.9,\n",
    "                   2.1, 3.3, 2.7, 3.8, 2.2])\n",
    "\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"The p-value is less than 0.05, indicating that there are significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than or equal to 0.05, indicating that there are no significant differences between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               sum_sq    df         F    PR(>F)\n",
      "C(Software)                 35.723737   2.0  4.579013  0.012956\n",
      "C(Experience)                0.010866   1.0  0.002786  0.958034\n",
      "C(Software):C(Experience)   17.753188   2.0  2.275576  0.109037\n",
      "Residual                   327.668211  84.0       NaN       NaN\n",
      "\n",
      "F-statistic for Software: 4.579012921588495\n",
      "p-value for Software: 0.012956222473477849\n",
      "\n",
      "F-statistic for Experience: 0.00278558658986327\n",
      "p-value for Experience: 0.9580335828750018\n",
      "\n",
      "F-statistic for Interaction: 2.275575954899061\n",
      "p-value for Interaction: 0.10903677121821326\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "software_programs = ['A', 'B', 'C']\n",
    "experience_levels = ['Novice', 'Experienced']\n",
    "\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'Time': np.random.normal(loc=10, scale=2, size=90),\n",
    "    'Software': np.repeat(software_programs, 30),\n",
    "    'Experience': np.tile(experience_levels, 45)\n",
    "})\n",
    "\n",
    "model = ols('Time ~ C(Software) * C(Experience)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "\n",
    "f_statistic_software = anova_table.loc['C(Software)', 'F']\n",
    "p_value_software = anova_table.loc['C(Software)', 'PR(>F)']\n",
    "f_statistic_experience = anova_table.loc['C(Experience)', 'F']\n",
    "p_value_experience = anova_table.loc['C(Experience)', 'PR(>F)']\n",
    "f_statistic_interaction = anova_table.loc['C(Software):C(Experience)', 'F']\n",
    "p_value_interaction = anova_table.loc['C(Software):C(Experience)', 'PR(>F)']\n",
    "\n",
    "print(\"\\nF-statistic for Software:\", f_statistic_software)\n",
    "print(\"p-value for Software:\", p_value_software)\n",
    "print(\"\\nF-statistic for Experience:\", f_statistic_experience)\n",
    "print(\"p-value for Experience:\", p_value_experience)\n",
    "print(\"\\nF-statistic for Interaction:\", f_statistic_interaction)\n",
    "print(\"p-value for Interaction:\", p_value_interaction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -4.531505106995775\n",
      "p-value: 2.976964741494067e-05\n",
      "The results are significant (p-value < 0.05), indicating that there is a significant difference in test scores between the two groups.\n",
      "\n",
      "Post-hoc Tukey's HSD test results:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "=======================================================\n",
      " group1    group2    meandiff p-adj lower  upper reject\n",
      "-------------------------------------------------------\n",
      "Control Experimental   4.0667   0.0 2.2703 5.863   True\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "control_group_scores = np.array([85, 78, 92, 88, 79, 81, 90, 87, 83, 89,\n",
    "                                  84, 82, 86, 80, 91, 88, 89, 90, 82, 85,\n",
    "                                  87, 88, 83, 81, 90, 79, 84, 82, 85, 88])\n",
    "experimental_group_scores = np.array([92, 86, 94, 90, 88, 89, 93, 87, 91, 85,\n",
    "                                      95, 87, 91, 88, 90, 86, 93, 88, 85, 89,\n",
    "                                      90, 92, 87, 84, 91, 89, 86, 88, 94, 90])\n",
    "\n",
    "t_statistic, p_value = ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "if p_value < 0.05:\n",
    "    print(\"The results are significant (p-value < 0.05), indicating that there is a significant difference in test scores between the two groups.\")\n",
    "    all_scores = np.concatenate([control_group_scores, experimental_group_scores])\n",
    "    group_labels = ['Control'] * len(control_group_scores) + ['Experimental'] * len(experimental_group_scores)\n",
    "    tukey_result = pairwise_tukeyhsd(all_scores, group_labels)\n",
    "    print(\"\\nPost-hoc Tukey's HSD test results:\")\n",
    "    print(tukey_result)\n",
    "else:\n",
    "    print(\"The results are not significant (p-value >= 0.05), indicating that there is no significant difference in test scores between the two groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a posthoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHISHEK\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\base\\model.py:1896: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "C:\\Users\\ABHISHEK\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\base\\model.py:1896: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 29, but rank is 5\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "C:\\Users\\ABHISHEK\\AppData\\Roaming\\Python\\Python311\\site-packages\\statsmodels\\base\\model.py:1896: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 58, but rank is 20\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       sum_sq    df             F    PR(>F)\n",
      "C(Store)         1.791996e-13   2.0  7.381217e-16  1.000000\n",
      "C(Day)           1.288030e+04  29.0  3.658887e+00  0.005902\n",
      "C(Store):C(Day)  2.385595e+04  58.0  3.388362e+00  0.000133\n",
      "Residual         7.283333e+03  60.0           NaN       NaN\n",
      "\n",
      "Interpretation:\n",
      "Since the p-value for Store and the interaction between Store and Day are both less than 0.05,\n",
      "we conclude that there are significant differences in daily sales between the three stores,\n",
      "and there is a significant interaction effect between Store and Day.\n",
      "\n",
      "Post-hoc Tukey's HSD test results:\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      "group1 group2 meandiff p-adj   lower    upper  reject\n",
      "-----------------------------------------------------\n",
      "     A      B  -6.1667 0.1883 -14.5085  2.1752  False\n",
      "     A      C -16.1667    0.0 -24.5085 -7.8248   True\n",
      "     B      C    -10.0 0.0146 -18.3419 -1.6581   True\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "store_A_sales = np.array([100, 110, 120, 115, 105, 100, 125, 130, 135, 110,\n",
    "                          105, 100, 115, 120, 125, 130, 135, 110, 115, 120,\n",
    "                          125, 130, 135, 110, 115, 120, 125, 130, 135, 110])\n",
    "store_B_sales = np.array([90, 95, 100, 105, 110, 115, 120, 125, 130, 135,\n",
    "                          90, 95, 100, 105, 110, 115, 120, 125, 130, 135,\n",
    "                          90, 95, 100, 105, 110, 115, 120, 125, 130, 135])\n",
    "store_C_sales = np.array([80, 85, 90, 95, 100, 105, 110, 115, 120, 125,\n",
    "                          80, 85, 90, 95, 100, 105, 110, 115, 120, 125,\n",
    "                          80, 85, 90, 95, 100, 105, 110, 115, 120, 125])\n",
    "\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Sales': np.concatenate([store_A_sales, store_B_sales, store_C_sales]),\n",
    "    'Store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
    "    'Day': np.repeat(np.arange(1, 31), 3)\n",
    "})\n",
    "\n",
    "model = ols('Sales ~ C(Store) + C(Day) + C(Store):C(Day)', data=data).fit()\n",
    "\n",
    "\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"Since the p-value for Store and the interaction between Store and Day are both less than 0.05,\")\n",
    "print(\"we conclude that there are significant differences in daily sales between the three stores,\")\n",
    "print(\"and there is a significant interaction effect between Store and Day.\")\n",
    "\n",
    "tukey_result = pairwise_tukeyhsd(data['Sales'], data['Store'])\n",
    "print(\"\\nPost-hoc Tukey's HSD test results:\")\n",
    "print(tukey_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
