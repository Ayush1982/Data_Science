{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Q1. Explain the concept of precision and recall in the context of classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Precision**:\n",
    "   - Precision measures the accuracy of positive predictions made by the model. It is defined as the ratio of true positive (TP) predictions to the total number of positive predictions made by the model, including both true positives and false positives (FP).\n",
    "   - Intuitively, precision answers the question: \"Of all the instances predicted as positive by the model, how many are actually positive?\" A high precision indicates that the model makes few false positive predictions, meaning that when it predicts an instance as positive, it is highly likely to be correct.\n",
    "\n",
    "2. **Recall**:\n",
    "   - Recall, also known as sensitivity or true positive rate (TPR), measures the ability of the model to correctly identify positive instances from the total actual positive instances. It is defined as the ratio of true positive (TP) predictions to the total number of actual positive instances, including both true positives and false negatives (FN).\n",
    "   - Intuitively, recall answers the question: \"Of all the actual positive instances, how many did the model correctly identify as positive?\" A high recall indicates that the model captures a large proportion of positive instances, minimizing the number of false negative predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. What is the F1 score and how is it calculated? How is it different from precision and recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score is a metric used to evaluate the performance of a classification model, particularly in binary classification tasks where the outcome can be categorized into two classes: positive and negative. It combines the precision and recall of the model into a single value, providing a balanced measure of the model's accuracy.\n",
    "\n",
    "### Calculation:\n",
    "The F1 score is calculated as the harmonic mean of precision and recall, where precision is the ratio of true positive predictions to the total number of positive predictions, and recall is the ratio of true positive predictions to the total number of actual positive instances.\n",
    "\n",
    "Mathematically, the F1 score is defined as:\n",
    "\n",
    "F1 = 2 X {(precision * recall) / (precision + recall)} \n",
    "\n",
    "### Differences from Precision and Recall:\n",
    "- **Precision**: Precision focuses on the accuracy of positive predictions made by the model. It measures the ratio of true positive predictions to the total number of positive predictions, including both true positives and false positives. Precision answers the question: \"Of all the instances predicted as positive by the model, how many are actually positive?\"\n",
    "- **Recall**: Recall, also known as sensitivity or true positive rate, measures the ability of the model to correctly identify positive instances from the total actual positive instances. It is defined as the ratio of true positive predictions to the total number of actual positive instances, including both true positives and false negatives. Recall answers the question: \"Of all the actual positive instances, how many did the model correctly identify as positive?\"\n",
    "\n",
    "The main difference between precision, recall, and the F1 score lies in their focus:\n",
    "- Precision emphasizes the quality of positive predictions, emphasizing the accuracy of the model's positive classifications.\n",
    "- Recall emphasizes the completeness of positive predictions, emphasizing the model's ability to capture all positive instances.\n",
    "- The F1 score balances precision and recall, providing a single metric that considers both false positives and false negatives. It is useful when there is an uneven class distribution or when false positives and false negatives have different consequences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. What is ROC and AUC, and how are they used to evaluate the performance of classification models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **ROC Curve**:\n",
    "   - The ROC curve is a graphical representation of the performance of a classification model across different threshold values for classification probabilities. It plots the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\n",
    "   - The true positive rate (TPR), also known as recall or sensitivity, represents the proportion of positive instances correctly classified as positive by the model.\n",
    "   - The false positive rate (FPR) represents the proportion of negative instances incorrectly classified as positive by the model.\n",
    "   - The ROC curve visualizes the trade-off between TPR and FPR as the classification threshold changes. A higher TPR and a lower FPR indicate better model performance.\n",
    "\n",
    "2. **AUC (Area Under the ROC Curve)**:\n",
    "   - AUC is a scalar value that quantifies the overall performance of a classification model by calculating the area under the ROC curve. It ranges from 0 to 1, where:\n",
    "     - AUC = 1 represents a perfect classifier that achieves a TPR of 1 and an FPR of 0 across all threshold settings.\n",
    "     - AUC = 0.5 represents a random classifier that performs no better than chance, where the ROC curve follows the diagonal line (TPR = FPR).\n",
    "     - AUC < 0.5 indicates a classifier that performs worse than random.\n",
    "   - The higher the AUC value, the better the model's ability to distinguish between positive and negative instances. AUC measures the model's discriminatory power across all possible threshold settings.\n",
    "\n",
    "3. **Interpretation**:\n",
    "   - A high AUC value (close to 1) indicates that the model has good discriminatory power and effectively separates positive and negative instances, regardless of the classification threshold.\n",
    "   - A low AUC value (close to 0.5) suggests that the model's performance is comparable to random guessing.\n",
    "   - ROC and AUC are particularly useful for evaluating the performance of models in imbalanced datasets or scenarios where the cost of false positives and false negatives varies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. How do you choose the best metric to evaluate the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Nature of the Problem**:\n",
    "   - Consider the nature of the classification problem. Is it a binary classification (two classes) or multiclass classification (more than two classes) problem? Different evaluation metrics are suitable for binary and multiclass classification tasks.\n",
    "\n",
    "2. **Class Distribution**:\n",
    "   - Examine the class distribution in the dataset. Is the dataset balanced (equal or similar number of instances in each class) or imbalanced (significant difference in the number of instances between classes)? Imbalanced datasets may require evaluation metrics that are robust to class imbalance.\n",
    "\n",
    "3. **Costs of Errors**:\n",
    "   - Understand the costs associated with different types of errors (false positives and false negatives). In some cases, one type of error may be more costly than the other. Choose evaluation metrics that align with the specific costs of errors in the problem domain.\n",
    "\n",
    "4. **Business Objectives**:\n",
    "   - Consider the business objectives or goals of the classification task. Are you more concerned about maximizing overall accuracy, minimizing false positives, maximizing true positives, or achieving a balance between precision and recall? Choose evaluation metrics that reflect the priorities and objectives of the business problem.\n",
    "\n",
    "5. **Interpretability**:\n",
    "   - Evaluate the interpretability of the chosen metric. Some metrics, such as accuracy and F1 score, provide a single scalar value that summarizes overall model performance, while others, such as precision-recall curve and ROC curve, provide more detailed insights into the trade-offs between different aspects of model performance.\n",
    "\n",
    "6. **Context of Use**:\n",
    "   - Consider the context in which the classification model will be deployed and used. Are there specific regulatory or industry standards that dictate the choice of evaluation metrics? Ensure that the chosen metric aligns with the context and requirements of the problem domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10 What is multiclass classification and how is it different from binary classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics of Multiclass Classification:\n",
    "1. **Multiple Classes**:\n",
    "   - In multiclass classification, there are three or more distinct classes or categories into which instances can be classified. Examples include classifying images of animals into categories such as \"cat,\" \"dog,\" \"bird,\" and \"horse.\"\n",
    "\n",
    "2. **Single Label Assignment**:\n",
    "   - Each instance in the dataset is assigned to one and only one class label. Unlike multilabel classification, where instances can belong to multiple classes simultaneously, multiclass classification involves single-label assignment.\n",
    "\n",
    "3. **One-vs-All (OvA) or One-vs-One (OvO) Approach**:\n",
    "   - Multiclass classification algorithms typically employ one of two strategies for handling multiple classes: One-vs-All (OvA) or One-vs-One (OvO). In the OvA approach, a separate binary classifier is trained for each class, treating that class as the positive class and the rest as the negative class. In the OvO approach, a binary classifier is trained for every pair of classes, and the class with the most votes is chosen as the final prediction.\n",
    "\n",
    "### Differences from Binary Classification:\n",
    "Binary classification, on the other hand, is a type of classification problem where the goal is to classify instances into one of two classes or categories: positive and negative. The key differences between multiclass classification and binary classification are as follows:\n",
    "\n",
    "1. **Number of Classes**:\n",
    "   - In binary classification, there are only two classes: positive and negative. In multiclass classification, there are three or more classes.\n",
    "\n",
    "2. **Single vs. Multiple Labels**:\n",
    "   - In binary classification, each instance is assigned a single label (either positive or negative). In multiclass classification, each instance is assigned a single label from multiple possible classes.\n",
    "\n",
    "3. **Model Complexity**:\n",
    "   - Multiclass classification often requires more complex models and strategies compared to binary classification. Handling multiple classes introduces additional complexity in model training and prediction.\n",
    "\n",
    "4. **Evaluation Metrics**:\n",
    "   - The evaluation metrics used for assessing model performance may differ between binary and multiclass classification tasks. While metrics like accuracy, precision, recall, and F1 score are commonly used for both types of classification tasks, they may be interpreted differently in the context of multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. Explain how logistic regression can be used for multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **One-vs-Rest (OvR) or One-vs-All (OvA) Approach**:\n",
    "   - In the OvR approach, also known as the OvA approach, logistic regression is applied multiple times, each time treating one class as the positive class and the rest of the classes as the negative class. For example, if there are ( K ) classes, ( K ) separate logistic regression classifiers are trained, and for each classifier, the instances belonging to the positive class are labeled as positive, and the instances belonging to the rest of the classes are labeled as negative.\n",
    "   - During prediction, the class with the highest predicted probability from the ( K ) classifiers is chosen as the final predicted class.\n",
    "\n",
    "2. **Multinomial Logistic Regression**:\n",
    "   - Multinomial logistic regression, also known as softmax regression, is a generalization of logistic regression to handle multiclass classification directly. Instead of modeling the probability of each class independently, softmax regression models the joint probability distribution over all classes using the softmax function.\n",
    "   - In multinomial logistic regression, the model learns a separate set of parameters for each class, and the softmax function is used to convert the raw scores into probabilities for each class. The class with the highest probability is predicted as the final output.\n",
    "\n",
    "3. **Regularization**:\n",
    "   - Regularization techniques like L1 or L2 regularization can be applied to logistic regression models to prevent overfitting and improve generalization performance in multiclass classification tasks.\n",
    "\n",
    "4. **Feature Engineering**:\n",
    "   - Feature engineering techniques such as one-hot encoding can be used to represent categorical variables in a format suitable for logistic regression models in multiclass classification tasks.\n",
    "\n",
    "5. **Evaluation Metrics**:\n",
    "   - Evaluation metrics commonly used for logistic regression in multiclass classification tasks include accuracy, precision, recall, F1 score, and confusion matrix-derived metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Describe the steps involved in an end-to-end project for multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on SDLC:\n",
    "\n",
    "1. **Define the Problem and Goals**:\n",
    "   - Clearly define the multiclass classification problem you want to solve and specify the goals and objectives of the project. Identify the classes or categories you want to predict and understand the significance of accurate classification in the problem domain.\n",
    "\n",
    "2. **Data Collection**:\n",
    "   - Gather the relevant data for the multiclass classification task. This may involve collecting data from various sources, such as databases, APIs, or external datasets. Ensure that the data is representative of the problem domain and contains features relevant to the classification task.\n",
    "\n",
    "3. **Data Preprocessing**:\n",
    "   - Preprocess the collected data to prepare it for model training. This may involve steps such as handling missing values, encoding categorical variables, scaling numerical features, and performing feature engineering or selection to extract relevant features for the classification task.\n",
    "\n",
    "4. **Exploratory Data Analysis (EDA)**:\n",
    "   - Conduct exploratory data analysis to gain insights into the characteristics of the data, understand the distribution of classes, visualize relationships between features, and identify potential patterns or trends that may inform the modeling process.\n",
    "\n",
    "5. **Split the Data**:\n",
    "   - Split the preprocessed data into training, validation, and test sets. The training set is used to train the classification model, the validation set is used to tune hyperparameters and evaluate model performance during training, and the test set is used to evaluate the final model's performance.\n",
    "\n",
    "6. **Model Selection**:\n",
    "   - Choose an appropriate classification algorithm or model for multiclass classification. Common algorithms include logistic regression, decision trees, random forests, support vector machines (SVM), gradient boosting, and neural networks. Consider the characteristics of the data, computational resources, and performance requirements when selecting the model.\n",
    "\n",
    "7. **Model Training**:\n",
    "   - Train the selected classification model using the training data. Use techniques such as cross-validation to optimize hyperparameters and ensure robust model performance. Monitor the model's training progress and performance metrics on the validation set.\n",
    "\n",
    "8. **Model Evaluation**:\n",
    "   - Evaluate the trained classification model using the test set to assess its performance on unseen data. Calculate evaluation metrics such as accuracy, precision, recall, F1 score, and confusion matrix-derived metrics to measure the model's effectiveness in correctly classifying instances across all classes.\n",
    "\n",
    "9. **Model Tuning and Optimization**:\n",
    "   - Fine-tune the classification model by adjusting hyperparameters, feature engineering techniques, or model architecture based on the evaluation results. Iterate on the model training and evaluation process to optimize performance and generalization.\n",
    "\n",
    "10. **Deployment**:\n",
    "    - Once satisfied with the model's performance, deploy the trained classification model into production or integrate it into the desired application or system. Consider factors such as scalability, latency, and security when deploying the model.\n",
    "\n",
    "11. **Monitoring and Maintenance**:\n",
    "    - Monitor the deployed classification model's performance in real-world scenarios and continue to evaluate its effectiveness over time. Perform regular maintenance and updates to the model as needed, incorporating new data and addressing drift or changes in the problem domain.\n",
    "\n",
    "12. **Documentation and Reporting**:\n",
    "    - Document the entire end-to-end project, including data collection, preprocessing steps, model selection, training, evaluation results, and deployment process. Prepare comprehensive reports or documentation summarizing the project's findings, insights, and recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7. What is model deployment and why is it important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model deployment is the process of integrating a trained machine learning model into a production environment where it can be used to make predictions or provide insights based on new, unseen data. It involves deploying the model to a server or platform accessible to end-users or other systems for real-time inference.\n",
    "\n",
    "### Importance of Model Deployment:\n",
    "\n",
    "1. **Operationalization**:\n",
    "   - Model deployment transforms a machine learning model from a research or development phase into a practical, operational asset that can provide value in real-world scenarios. It allows organizations to leverage the predictive power of machine learning models to make informed decisions, automate tasks, or improve business processes.\n",
    "\n",
    "2. **Real-time Predictions**:\n",
    "   - Deploying a machine learning model enables real-time predictions or inferences based on new, incoming data. This is essential for applications where timely decision-making or automated actions are required, such as fraud detection, recommendation systems, predictive maintenance, and medical diagnosis.\n",
    "\n",
    "3. **Scalability**:\n",
    "   - Deploying a model to a production environment allows for scalability to handle large volumes of data and accommodate a growing number of users or requests. Cloud-based deployment platforms offer scalable infrastructure and resources for hosting and serving machine learning models to handle varying workloads efficiently.\n",
    "\n",
    "4. **Integration with Existing Systems**:\n",
    "   - Model deployment facilitates integration with existing software systems, applications, or workflows within an organization. By exposing model endpoints or APIs, other systems can interact with the deployed model to incorporate predictive capabilities seamlessly into their operations.\n",
    "\n",
    "5. **Feedback Loop and Model Monitoring**:\n",
    "   - Deployed models enable the establishment of a feedback loop, where predictions or outcomes generated by the model are monitored and evaluated in real-time. This feedback loop allows for continuous model monitoring, performance assessment, and iterative improvements based on observed behavior and changing data patterns.\n",
    "\n",
    "6. **Decision Support and Automation**:\n",
    "   - Deployed models provide decision support and automation capabilities by leveraging predictive insights to inform decision-making processes or automate routine tasks. This can lead to improved efficiency, accuracy, and consistency in decision-making across various domains and industries.\n",
    "\n",
    "7. **Value Generation**:\n",
    "   - Model deployment is crucial for realizing the value of machine learning investments and translating predictive analytics into tangible outcomes, such as increased revenue, cost savings, improved customer satisfaction, or enhanced operational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Q8. Explain how multi-cloud platforms are used for model deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-cloud platforms is the use of multiple cloud computing providers or platforms to deploy and manage applications, services, and resources. In the context of model deployment for machine learning, multi-cloud platforms offer several advantages and capabilities that enhance flexibility, scalability, reliability, and performance. Here's how multi-cloud platforms are used for model deployment:\n",
    "\n",
    "1. **Vendor Diversity and Avoidance of Vendor Lock-in**:\n",
    "   - Multi-cloud platforms allow organizations to leverage multiple cloud computing providers, such as Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), IBM Cloud, and others. By distributing workloads across different cloud providers, organizations can avoid vendor lock-in and benefit from vendor diversity to access a broader range of services, features, and pricing options.\n",
    "\n",
    "2. **High Availability and Disaster Recovery**:\n",
    "   - Deploying models on multiple cloud platforms enables redundancy and fault tolerance, ensuring high availability and reliability of services. Organizations can design multi-cloud architectures with failover mechanisms and disaster recovery strategies to minimize downtime and maintain service continuity in the event of infrastructure failures or service disruptions in any single cloud provider.\n",
    "\n",
    "3. **Geographical Reach and Data Sovereignty**:\n",
    "   - Multi-cloud platforms enable organizations to deploy models and services in multiple geographic regions or data centers offered by different cloud providers. This geographic diversity allows organizations to comply with data sovereignty regulations, address latency concerns, and optimize performance by deploying resources closer to end-users or target markets.\n",
    "\n",
    "4. **Hybrid and Multi-Cloud Architectures**:\n",
    "   - Multi-cloud platforms support hybrid and multi-cloud architectures, allowing organizations to seamlessly integrate on-premises infrastructure with cloud resources and services across multiple cloud providers. This flexibility enables organizations to leverage existing investments in on-premises infrastructure while benefiting from the scalability, agility, and innovation of cloud services.\n",
    "\n",
    "5. **Cost Optimization and Resource Management**:\n",
    "   - Multi-cloud platforms provide opportunities for cost optimization and resource management by leveraging competitive pricing, spot instances, and discounts offered by different cloud providers. Organizations can dynamically allocate resources, optimize workload placement, and implement cost management strategies across multiple cloud platforms to achieve cost savings and operational efficiency.\n",
    "\n",
    "6. **Service Integration and Interoperability**:\n",
    "   - Multi-cloud platforms facilitate service integration and interoperability by leveraging open standards, APIs, and middleware solutions that enable seamless communication and data exchange between different cloud providers and services. This interoperability allows organizations to build distributed applications, leverage best-of-breed services, and avoid vendor lock-in.\n",
    "\n",
    "7. **Compliance and Risk Management**:\n",
    "   - Multi-cloud platforms enable organizations to diversify risk, enhance compliance, and strengthen security posture by distributing workloads and data across multiple cloud providers. Organizations can implement robust security controls, data encryption, and compliance frameworks to mitigate risks related to data breaches, regulatory requirements, and cybersecurity threats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9. Discuss the benefits and challenges of deploying machine learning models in a multi-cloud environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits:\n",
    "\n",
    "1. **Vendor Diversity**:\n",
    "   - Leveraging multiple cloud providers allows organizations to benefit from the unique offerings, services, and pricing models of each provider. This diversity provides flexibility in choosing the most suitable cloud services for specific requirements and workloads.\n",
    "\n",
    "2. **High Availability and Redundancy**:\n",
    "   - Multi-cloud deployments enable redundancy and fault tolerance, ensuring high availability of services by distributing workloads across multiple cloud providers and regions. This redundancy minimizes the risk of downtime and service disruptions.\n",
    "\n",
    "3. **Cost Optimization**:\n",
    "   - Multi-cloud environments offer opportunities for cost optimization by leveraging competitive pricing, discounts, and cost management strategies across multiple cloud providers. Organizations can optimize costs by dynamically allocating resources and leveraging spot instances or discounted pricing options.\n",
    "\n",
    "4. **Performance Optimization**:\n",
    "   - Multi-cloud deployments allow organizations to optimize performance by deploying resources closer to end-users or target markets in different geographic regions. This geographical diversity improves latency, enhances user experience, and ensures regulatory compliance with data sovereignty requirements.\n",
    "\n",
    "5. **Risk Mitigation**:\n",
    "   - Diversifying workloads across multiple cloud providers reduces the risk of vendor lock-in and mitigates the impact of service outages or disruptions from any single cloud provider. This risk diversification enhances resilience and business continuity.\n",
    "\n",
    "6. **Scalability and Elasticity**:\n",
    "   - Multi-cloud environments offer scalability and elasticity by providing access to a broad range of cloud services, resources, and capacity across multiple providers. Organizations can scale resources up or down dynamically to meet changing demands and workload requirements.\n",
    "\n",
    "### Challenges:\n",
    "\n",
    "1. **Complexity and Management Overhead**:\n",
    "   - Managing resources, configurations, and workflows across multiple cloud providers introduces complexity and management overhead. Organizations must deal with disparate tools, APIs, and deployment pipelines, leading to increased operational complexity and potential challenges in monitoring and troubleshooting.\n",
    "\n",
    "2. **Data Integration and Interoperability**:\n",
    "   - Integrating data and services across multiple cloud providers requires robust data integration and interoperability solutions. Ensuring seamless communication and data exchange between different cloud environments can be challenging, especially when dealing with heterogeneous data formats and protocols.\n",
    "\n",
    "3. **Security and Compliance**:\n",
    "   - Ensuring consistent security controls, data protection measures, and compliance frameworks across multiple cloud environments is challenging. Organizations must implement robust security practices, encryption mechanisms, and compliance policies to mitigate risks related to data breaches, regulatory requirements, and cybersecurity threats.\n",
    "\n",
    "4. **Vendor Lock-in Risk**:\n",
    "   - While multi-cloud environments aim to avoid vendor lock-in, organizations may still face challenges related to proprietary APIs, services, or dependencies that limit interoperability and portability between cloud providers. This risk of vendor lock-in can hinder flexibility and hinder migration efforts.\n",
    "\n",
    "5. **Resource Fragmentation and Overprovisioning**:\n",
    "   - Fragmentation of resources across multiple cloud providers can lead to resource sprawl, overprovisioning, and inefficient resource utilization. Organizations must carefully manage resource allocation, optimize workload placement, and implement cost management strategies to avoid unnecessary expenses.\n",
    "\n",
    "6. **Data Governance and Sovereignty**:\n",
    "   - Managing data governance, privacy, and sovereignty across multiple cloud environments requires careful consideration of regulatory requirements, data residency laws, and data protection measures. Ensuring compliance with data privacy regulations and maintaining data sovereignty can be challenging in a multi-cloud environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
