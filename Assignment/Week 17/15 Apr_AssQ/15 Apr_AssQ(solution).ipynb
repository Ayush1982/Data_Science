{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. You are working on a machine learning project where you have a dataset containing numerical and categorical features. You have identified that some of the features are highly correlated and there are missing values in some of the columns. You want to build a pipeline that automates the feature engineering process and handles the missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df=sns.load_dataset('tips')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "df['time']=encoder.fit_transform(df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.time.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(labels=['time'],axis=1)\n",
    "y=df.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       "       ..\n",
       " 239    0\n",
       " 240    0\n",
       " 241    0\n",
       " 242    0\n",
       " 243    0\n",
       " Name: time, Length: 244, dtype: int32,\n",
       "    total_bill   tip     sex smoker  day  size\n",
       " 0       16.99  1.01  Female     No  Sun     2\n",
       " 1       10.34  1.66    Male     No  Sun     3\n",
       " 2       21.01  3.50    Male     No  Sun     3\n",
       " 3       23.68  3.31    Male     No  Sun     2\n",
       " 4       24.59  3.61  Female     No  Sun     4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use an automated feature selection method to identify the important features in the dataset.\n",
    "- Create a numerical pipeline that includes the following steps:\n",
    "- Impute the missing values in the numerical columns using the mean of the column values.\n",
    "- Scale the numerical columns using standardisation.\n",
    "- Create a categorical pipeline that includes the following steps.\n",
    "- Impute the missing values in the categorical columns using the most frequent value of the column.\n",
    "- One-hot encode the categorical columns.\n",
    "- Combine the numerical and categorical pipelines using a ColumnTransformer.\n",
    "- Use a Random Forest Classifier to build the final model.\n",
    "- Evaluate the accuracy of the model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['sex', 'smoker','day']\n",
    "numerical_features = ['total_bill', 'tip','size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define feature selection model (Random Forest Classifier in this case)\n",
    "feature_selection_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Define numerical pipeline\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define categorical pipeline\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine numerical and categorical pipelines using ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_features),  # numerical_features: list of numerical feature column indices\n",
    "    ('cat', categorical_pipeline, categorical_features)  # categorical_features: list of categorical feature column indices\n",
    "])\n",
    "\n",
    "# Build final pipeline with feature selection and Random Forest Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(feature_selection_model)),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Fit pipeline on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate accuracy on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of each step:\n",
    "\n",
    "1. **Feature Selection**: We use a Random Forest Classifier as the feature selection model to automatically select important features from the dataset.\n",
    "\n",
    "2. **Numerical Pipeline**: Impute missing values in numerical columns using the mean of the column values and scale the numerical columns using standardization.\n",
    "\n",
    "3. **Categorical Pipeline**: Impute missing values in categorical columns using the most frequent value of the column and perform one-hot encoding.\n",
    "\n",
    "4. **Column Transformer**: Combine the numerical and categorical pipelines using ColumnTransformer.\n",
    "\n",
    "5. **Final Pipeline**: Build the final pipeline consisting of the preprocessor (ColumnTransformer), feature selection step, and the Random Forest Classifier.\n",
    "\n",
    "6. **Model Training**: Fit the pipeline on the training data.\n",
    "\n",
    "7. **Model Evaluation**: Evaluate the accuracy of the model on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris # 1\n",
    "from sklearn.model_selection import train_test_split # 2\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier #2\n",
    "from sklearn.linear_model import LogisticRegression # 1\n",
    "from sklearn.pipeline import Pipeline # 2 \n",
    "from sklearn.preprocessing import StandardScaler # 2\n",
    "from sklearn.metrics import accuracy_score # 2\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "random_forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "logistic_regression_clf = LogisticRegression(random_state=42)\n",
    "\n",
    "random_forest_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('random_forest', random_forest_clf)\n",
    "])\n",
    "\n",
    "logistic_regression_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_regression', logistic_regression_clf)\n",
    "])\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('rf', random_forest_pipeline), ('lr', logistic_regression_pipeline)],\n",
    "    voting='hard'  \n",
    ")\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = voting_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
